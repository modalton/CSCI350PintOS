       	       	    +---------------------------+
		    |		CS 140		|
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	   DESIGN DOCUMENT	|
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct page_entry
{
	void* vaddr;
	
	struct file* file;
	uint32_t read_bytes;
	uint32_t zero_bytes;
	off_t offset;

	uint8_t dirty_bit;
	bool writeable;
	bool loaded;
	enum entry_type type;

	size_t swap_slot_index;


	struct hash_elem hash_elem;
};

This is the main data structure entry for tracking these basic page characteristics. A hash table of these entries is kept for each thread in thier supplementary hash table.

struct frame_elem
{
	//do i need addr like pintos ex?
	void* frame;
	uint32_t* addr;
	struct page_entry* page_entry;
	uint32_t* pagedir;
	struct hash_elem hash_elem;
};

This is a frame elem, kept in a master global frame table. Has a pointer to which page entry is using it. While a list would've made for a more accurate LRU, I used a hash table for speed.

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

We'll take the rounded down user virtual address and look it up in our processes supplemental page table. This will give us the entry and then we use frame_alloc to grab us a frame. This is where we will locate the frame; the function will evict a frame is none are available or it will just do a normal allocation. Install page will put them together.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We use virtual addresses in kernel space, proper vaddr exception handling, and the supplemental page table to load pages so we actually avoid this. 

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?
I actually thing the palloc.h functions we use in frame_alloc have locks to preseve thier state so we dont have to worry about races. But just in case we have a master frame table lock used for evictions and allocations

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

The implementation slides were pretty clear that alot of these data structures needed to be sepereate, thread safe, communicable, and organized so this explains pretty much every seperate data structure and the variables they need to maintain to fulfill these requirements

		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

*see frame entry above

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We scan through and check if it's accessed and dirty, if not so we have eviction candidates. On the scan it it's not both then we flip the accessed bit so on another we can potentially get another hit. This isn't a perfect LRU because I used a hash table but it's pretty close

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

We keep a page_entry pointer in our frame entry as shown above. So we have the virtual address mapping as well as the hash elem for it's container in the thread struct. We could use the vaddr/page_entry mapping to go through threads and clear page upon finding it. But since we can view the thread in the spt entry functions, it would probably be faster to put a new pointer to our parent thread in the page_entry struct. That way we could instantly tell the parent of a page and have full access to thier page table struct. 

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

With push being the biggest allowed @ 32 bytes below the stack pointer, any virtual address in that range will be valid, anything below invalid. So if we have addr in range and our stack is in growable range we are allowed to grow it to make room for new memory

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

We use a global struct with locks for our swap and frame tables. Swaps isn't fully implemented yet, since it would be more of a precaution since bitmaps internals have an exclusive lock. The overall implementation is the same, the access is internal to the class, so while different processes may be calling the class functions, there's no chance of the lock being held in anything other classes operation. And with the process class never trying to acquire both swap and frame locks at the same time we can avoid circular waiting

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

We have a singular lock for our frame page table. We also require the lock at the start of our functions like frame_evict. So even if a page faults, goes to thier supplementary page table they would have to wait if somoene other process is performing actions on the global page table. This preserves it's state and avoids a race between any processes.

I also belive the design and implmentation of page fualt makes it so that if Ps kernel thread is reading the data in the function then Qs kernel page would fault and go to the supplemental page table entry and read the frame back in


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

Actually my imperfect LRU implementation makes this situation a bit more likely and would require a seperate evicatable attribute to prevent this 

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

I think my program, especially with its global structures, locks, and reliance and specific variables to prevent deadlock, my design leans more towards the single long implementation. My kind of guiding principle for desigining this was silimar to the books recomended practice of starting with one lock and implmenting more little by little to gain additional performance.

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct mmentry
{
	struct file* file;
	void* ptr;
	int mapid;
	int totalpgs;
	
	struct hash_elem hash_elem;
};

Pretty self explanitory struct variables for a memory mapped file. The id, mapped file, starting addr, and the number of pages for said memory mapping. A hash table of these are in every thread 

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

Both types of files are loaded in the pintos specified lazy way. Reading from the mmaped file is nearly identical to the executable for a page fault. But the un/mmap functionality is all done through syscalls. During it's unmaping we go through and write back and dirty pages if necessary. 

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

We get the filesize and from the starting address go one page at a time and see if we have any overlaps. We must go over the page table and spt to make sure we don't have an overlap.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

Having never even used memory mapped files in applications or really being all too familiar with it, I strived to keep them sepereation for clarity. Quite frankly thier similarity is the reason I did it because it just makes it easier to get confused and find mistakes.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
